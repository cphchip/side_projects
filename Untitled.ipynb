{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6447fd58",
   "metadata": {},
   "source": [
    "# cs7324 Lab 2 - Exploring Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e2037",
   "metadata": {},
   "source": [
    "## 1. Business Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca73303",
   "metadata": {},
   "source": [
    "\"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton (http://www.cs.toronto.edu/~kriz/cifar.html).\"\n",
    "\n",
    "The CIFAR-10 dataset was selected for this lab. The full dataset is a collection of 60,000 images across 10 classes, each 32x32 pixels. It is further divided into subsets of five, 10,000 image training batches and one, 1,000 image test batch. Each image is in color so the data consists of \"a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image (https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "To meet the requirments of the lab only one, 10,000 image subset is used. \n",
    "\n",
    "The data was originally collected for machine learning purposes by the Canadian Institute for Advanced Research. Many research papers have been written regarding application of a variety of machine learning techniques utilizing this dataset (https://en.wikipedia.org/wiki/CIFAR-10). While this dataset is focused on academia and research, a business case could be made for datasets like this to be used to create image recognition software for web search engines, thereby enabling them to attact users and sell advertisements. Specifically the CIFAR-10 dataset can be used to train a computer to recognize images of airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and large trucks (https://www.cs.toronto.edu/~kriz/cifar.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42dee7",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861eb607",
   "metadata": {},
   "source": [
    "This data is formatted in the pickle format which requires unpickling. Below is a function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41976437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n"
     ]
    }
   ],
   "source": [
    "# Source http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import datasets as ds\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "ds = unpickle(r\"C:\\Users\\Chip\\source\\repos\\cs7324_code\\Lab 2\\cifar-10-batches-py\\data_batch_1\")\n",
    "print(ds.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa3e0b",
   "metadata": {},
   "source": [
    "Now we'll prep the data for PCA and RPCA analysis by setting appropriate variables to portions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66473e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 10000\n",
      "n_features: 3072\n"
     ]
    }
   ],
   "source": [
    "# Source: In class lecture and flipped assignment\n",
    "X = ds[b'data'] # Assign feature vectors to 'X'\n",
    "y = np.array(ds[b'labels']) # Assign target values to y, we'll be trying to predict these later on\n",
    "\n",
    "# This data was a 1D array to start, reshaping it to create a column vector of y values\n",
    "y = y.reshape(10000, 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# print(np.sum(~np.isfinite(X)))\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_features: {}\".format(n_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ac2b4",
   "metadata": {},
   "source": [
    "Since each row represents the red, green blue values for a picture, and that there are 1024 total pixels in a 32x32 image we see from above that there are 3072 features and 10,000 images in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d286ea",
   "metadata": {},
   "source": [
    "## 3. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4817e",
   "metadata": {},
   "source": [
    "We'll now look at trying to reduce features by performing PCA on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d47e29",
   "metadata": {},
   "source": [
    "**How many features should we decompose to???**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e229e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: In class lecture\n",
    "\n",
    "# lets do some PCA of the features and go from 1850 features to 20 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, X.shape[0]))\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "%time pca.fit(X.copy())\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebf181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
